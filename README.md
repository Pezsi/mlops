# Wine Quality MLOps Project

Production-ready machine learning application for wine quality prediction with complete MLOps infrastructure.

## Overview

Full ML pipeline for predicting wine quality using Random Forest and Gradient Boosting models, with MLflow tracking, REST APIs, and comprehensive testing.

### Key Features

- **Two ML Models** - Random Forest & Gradient Boosting
- **MLflow Integration** - Experiment tracking, model registry
- **Two REST APIs** - FastAPI (async) & Flask-RESTX
- **Docker Containerization** - Multi-container orchestration with Docker Compose
- **Apache Airflow** - Automated training pipelines and model deployment
- **GCP Cloud Run** - Serverless deployment with CI/CD (GitHub Actions)
- **Streamlit Dashboard** - Real-time monitoring and visualization
- **Evidently Integration** - Data drift and model drift detection
- **91+ Tests** - Unit, integration, and API tests
- **PEP8 Compliant** - 0 linting errors
- **Production Ready** - Full MLSecOps infrastructure

## Quick Start

### Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Train models
python main.py --pipeline compare

# Start API
python fastapi_app.py        # or python flask_app.py

# View experiments
mlflow ui --port 5000

# Run tests
pytest tests/ -v
```

### Docker Deployment (Recommended)

```bash
# Start complete MLOps platform
docker-compose up -d

# Access services:
# - Airflow UI: http://localhost:8081 (admin/admin)
# - MLflow UI: http://localhost:5000
# - FastAPI: http://localhost:8000/docs
# - Monitoring: http://localhost:8501

# View logs
docker-compose logs -f

# Stop all services
docker-compose down
```

For detailed deployment instructions, see [DOCKER_DEPLOYMENT.md](DOCKER_DEPLOYMENT.md)

## Project Structure

```
wine_quality_mlops/
â”œâ”€â”€ config.py                  # Configuration & hyperparameters
â”œâ”€â”€ main.py                    # Pipeline orchestrator
â”œâ”€â”€ fastapi_app.py             # FastAPI REST API (547 lines)
â”œâ”€â”€ flask_app.py               # Flask-RESTX REST API (637 lines)
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ load_data.py           # Data loading & splitting
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ preprocessing.py       # Feature preprocessing
â”‚   â”œâ”€â”€ train.py               # Model training
â”‚   â””â”€â”€ evaluate.py            # Model evaluation
â”‚
â”œâ”€â”€ tests/                     # 91+ tests
â”‚   â”œâ”€â”€ test_load_data.py      # 17 tests
â”‚   â”œâ”€â”€ test_preprocessing.py  # 26 tests
â”‚   â”œâ”€â”€ test_train.py          # 23 tests
â”‚   â”œâ”€â”€ test_evaluate.py       # 25 tests
â”‚   â”œâ”€â”€ test_integration.py    # 8 tests
â”‚   â”œâ”€â”€ test_fastapi.py        # 15+ tests
â”‚   â””â”€â”€ test_flask_app.py      # 15+ tests
â”‚
â”œâ”€â”€ airflow/                   # Airflow orchestration
â”‚   â”œâ”€â”€ dags/                  # DAG definitions
â”‚   â”‚   â””â”€â”€ train_wine_quality_dag.py  # Automated training pipeline
â”‚   â”œâ”€â”€ logs/                  # Airflow logs
â”‚   â””â”€â”€ Dockerfile.airflow     # Airflow container
â”‚
â”œâ”€â”€ monitoring/                # Monitoring dashboard
â”‚   â””â”€â”€ app.py                 # Streamlit monitoring app
â”‚
â”œâ”€â”€ models/                    # Trained models
â”œâ”€â”€ mlruns/                    # MLflow experiments
â”œâ”€â”€ logs/                      # Training logs
â”‚
â”œâ”€â”€ Dockerfile                 # Main application container
â”œâ”€â”€ Dockerfile.streamlit       # Monitoring container
â”œâ”€â”€ docker-compose.yml         # Multi-service orchestration
â”œâ”€â”€ environment.yml            # Conda environment
â””â”€â”€ DOCKER_DEPLOYMENT.md       # Deployment guide
```

## ML Pipeline

### Training

```bash
# Compare both models
python main.py --pipeline compare

# Train specific model
python main.py --pipeline rf    # Random Forest
python main.py --pipeline gb    # Gradient Boosting
```

### Pipeline Steps

1. **Data Loading** - UCI Wine Quality dataset
2. **Splitting** - 80/20 train/test (stratified)
3. **Preprocessing** - StandardScaler, optional PCA
4. **Training** - GridSearchCV with 10-fold CV
5. **Evaluation** - RÂ², MSE, RMSE, MAE
6. **Logging** - MLflow tracking
7. **Persistence** - Model saving

### Model Performance

| Model | RÂ² Score | RMSE | Training Time |
|-------|----------|------|---------------|
| Random Forest | ~0.47 | ~0.58 | 1-2 min |
| Gradient Boosting | ~0.49 | ~0.57 | 2-3 min |

## MLflow

### Start MLflow UI

```bash
mlflow ui --port 5000
# Open http://localhost:5000
```

### Tracked Information

- Hyperparameters (GridSearchCV)
- Cross-validation scores
- Test metrics (RÂ², MSE, RMSE, MAE)
- Model artifacts
- Dataset info

## REST APIs

### FastAPI (Modern, Async)

```bash
python fastapi_app.py
# Docs: http://localhost:8000/docs
```

**Features:** Async support, Pydantic validation, high performance

### Flask-RESTX (Traditional)

```bash
python flask_app.py
# Docs: http://localhost:8000/docs/
```

**Features:** Namespace organization, mature ecosystem

### API Endpoints

```
GET  /                     # Welcome
GET  /health               # Health check
GET  /features             # Feature list
GET  /models               # Available models
GET  /metrics/{model}      # Model metrics

POST /predict              # Single prediction
POST /predict/batch        # Batch predictions
POST /model/train          # Train model
POST /model/predict        # Alias endpoint
```

### Example Request

```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{
    "features": {
      "fixed_acidity": 7.4,
      "volatile_acidity": 0.7,
      "citric_acid": 0.0,
      "residual_sugar": 1.9,
      "chlorides": 0.076,
      "free_sulfur_dioxide": 11.0,
      "total_sulfur_dioxide": 34.0,
      "density": 0.9978,
      "pH": 3.51,
      "sulphates": 0.56,
      "alcohol": 9.4
    },
    "model_name": "rf"
  }'
```

**Response:**
```json
{
  "quality_prediction": 5.67,
  "model_used": "rf"
}
```

## Testing

### Run Tests

```bash
# All tests
pytest tests/ -v

# Specific modules
pytest tests/test_load_data.py -v
pytest tests/test_integration.py -v

# API tests
pytest tests/test_fastapi.py -v
pytest tests/test_flask_app.py -v

# With coverage
pytest tests/ --cov=. --cov-report=html
```

### Test Coverage

- **91+ tests total**
- Unit tests for all modules
- Integration tests for pipeline
- API endpoint tests
- 100% PEP8 compliant

## Installation

### Prerequisites

- Python 3.8+
- pip

### Setup

```bash
# Clone repository
cd wine_quality_mlops

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# Train models
python main.py --pipeline compare

# Verify
pytest tests/ -v
```

## Configuration

Edit `config.py` to customize:

```python
# Data
TEST_SIZE = 0.2
RANDOM_STATE = 123

# Models
MODEL_PATH = Path("models/rf_regressor.pkl")
GB_MODEL_PATH = Path("models/gb_regressor.pkl")

# Hyperparameters
HYPERPARAM_GRID = {
    "randomforestregressor__max_features": ["sqrt", "log2"],
    "randomforestregressor__max_depth": [None, 5, 3, 1],
}

# API
API_HOST = "0.0.0.0"
API_PORT = 8000
```

## Usage Examples

### Python API

```python
from data.load_data import load_and_split_data
from src.preprocessing import create_preprocessing_pipeline
from src.train import train_model_with_grid_search
from src.evaluate import evaluate_model

# Load data
X_train, X_test, y_train, y_test = load_and_split_data()

# Train
pipeline = create_preprocessing_pipeline()
model = train_model_with_grid_search(pipeline, X_train, y_train)

# Evaluate
metrics = evaluate_model(model, X_test, y_test)
print(f"RÂ²: {metrics['r2_score']:.4f}")
```

### REST API

```python
import requests

response = requests.post(
    "http://localhost:8000/predict",
    json={
        "features": {...},
        "model_name": "rf"
    }
)
print(response.json())
```

## Deployment

### Docker

```dockerfile
FROM python:3.10-slim
WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt
COPY . .
EXPOSE 8000
CMD ["uvicorn", "fastapi_app:app", "--host", "0.0.0.0"]
```

```bash
docker build -t wine-quality-api .
docker run -p 8000:8000 wine-quality-api
```

### Production

```bash
# FastAPI with Gunicorn
gunicorn fastapi_app:app \
  --workers 4 \
  --worker-class uvicorn.workers.UvicornWorker \
  --bind 0.0.0.0:8000

# Flask with Gunicorn
gunicorn flask_app:flask_app \
  --workers 4 \
  --bind 0.0.0.0:8000
```

## Code Quality

```bash
# PEP8 check
flake8 . --exclude=venv,mlruns
# Result: 0 errors âœ…

# Format code
black . --exclude=venv

# Type checking
mypy . --exclude=venv
```

## Project Metrics

- **Total Code:** ~3,500 lines
- **Test Code:** ~1,300 lines
- **API Code:** ~1,800 lines
- **Tests:** 91+
- **PEP8 Errors:** 0

## Technology Stack

**ML/Data:**
- scikit-learn, pandas, numpy

**MLOps:**
- MLflow - Experiment tracking & model registry
- Apache Airflow - Workflow orchestration
- Evidently - Data & model drift detection

**APIs:**
- FastAPI - Async REST API
- Flask-RESTX - Traditional REST API

**Containerization:**
- Docker - Application containerization
- Docker Compose - Multi-service orchestration

**Monitoring:**
- Streamlit - Interactive dashboards
- Plotly - Data visualization

**Testing:**
- pytest, httpx

**Quality:**
- black, flake8

**Databases:**
- PostgreSQL - Airflow metadata
- Redis - Airflow message broker

## Airflow Automation

### Airflow MLOps Platform

A teljes projekt egy production-ready MLOps rendszer Apache Airflow orchestrÃ¡ciÃ³val. Az alÃ¡bbi szolgÃ¡ltatÃ¡sokat tartalmazza:

**SzolgÃ¡ltatÃ¡sok:**
- **Airflow Webserver/Scheduler** (8081) - DAG kezelÃ©s Ã©s Ã¼temezÃ©s
- **MLOps Metadata DB** (PostgreSQL:5433) - DedikÃ¡lt metadata tracking
- **MLflow** (5000) - Model tracking Ã©s registry
- **Webhook API** (8080) - External triggers REST API-val
- **Streamlit Dashboard** (8501) - Real-time monitoring
- **Redis** - Airflow message broker
- **PostgreSQL** - Airflow metadata

### DAG-ok ÃttekintÃ©se

A projekt **5 kÃ¼lÃ¶nbÃ¶zÅ‘ DAG**-ot tartalmaz kÃ¼lÃ¶nbÃ¶zÅ‘ trigger tÃ­pusokkal:

#### 1. `daily_model_training_with_notification`
**Trigger:** Schedule-based (napi 2:00 AM)

**FunkciÃ³k:**
- Automatikus model training MLflow logging-gal
- Metadata tracking PostgreSQL adatbÃ¡zisba
- Intelligent model comparison (RÂ² Ã©s RMSE alapjÃ¡n)
- Multi-stage deployment (Staging â†’ Production)
- Multi-channel notifications (Email, Slack, Database)
- Comprehensive error handling Ã©s retry logic

**Workflow:**
```
Train Model â†’ Compare with Production â†’ Better?
   â†“ Yes                                    â†“ No
Deploy to Staging                  Send Warning Notification
   â†“
Deploy to Production
   â†“
Send Success Notification
```

**Callbacks:**
- `on_success_callback` - Task sikeres befejezÃ©sekor
- `on_failure_callback` - Task hiba esetÃ©n (Email + Slack + DB)
- `on_retry_callback` - Retry kÃ­sÃ©rletkor (Slack + DB)

#### 2. `dataset_sensor_event_trigger`
**Trigger:** Event-based (FileSensor)

**FunkciÃ³k:**
- Automatikusan detektÃ¡lja Ãºj dataset fÃ¡jlokat (`/opt/airflow/data/incoming`)
- Dataset validÃ¡ciÃ³ (schema, quality checks)
- **Data drift detection:**
  - Kolmogorov-Smirnov test numerikus feature-Ã¶kre
  - Population Stability Index (PSI) szÃ¡mÃ­tÃ¡s
  - Threshold: PSI > 0.2 â†’ drift detected
- Conditional model retraining trigger drift esetÃ©n
- Processed fÃ¡jl mozgatÃ¡s

#### 3. `model_deployment_pipeline`
**Trigger:** Schedule + ExternalTaskSensor (napi 4:00 AM)

**FunkciÃ³k:**
- VÃ¡r a training DAG befejezÃ©sÃ©re (`ExternalTaskSensor`)
- Comprehensive model evaluation
- A/B test setup
- Multi-stage deployment
- Deployment report generation
- Stakeholder notifications

#### 4. `data_pipeline_orchestrator`
**Trigger:** Schedule-based (napi 1:00 AM)

**FunkciÃ³k:**
- TÃ¶bb data pipeline orchestrÃ¡lÃ¡sa parallel
- Complex dependencies kezelÃ©se
- AggregÃ¡lt adatfeldolgozÃ¡s
- Conditional training trigger

#### 5. `webhook_triggered_training`
**Trigger:** API/Webhook (on-demand)

**FunkciÃ³k:**
- REST API triggered training custom paramÃ©terekkel
- Configuration parsing Ã©s validation
- Training szÃ¼ksÃ©gessÃ©g ellenÅ‘rzÃ©s
- Deployment target environment-be
- Callback URL support

**API hasznÃ¡lat:**
```bash
curl -X POST http://localhost:8080/trigger/training \
  -H "Content-Type: application/json" \
  -H "X-API-Key: mlops-secret-key-2025" \
  -d '{
    "model_name": "wine_quality_rf_model",
    "trigger_source": "ci_cd",
    "force_training": true,
    "hyperparameters": {"n_estimators": 200}
  }'
```

### Metadata Tracking System

**PostgreSQL adatbÃ¡zis 14 tÃ¡blÃ¡val:**

**FÅ‘ tÃ¡blÃ¡k:**
- `model_runs` - Training futÃ¡sok tracking
- `model_metrics` - MetrikÃ¡k (RÂ², RMSE, MAE, stb.)
- `model_parameters` - HyperparamÃ©terek
- `dataset_versions` - Dataset verziÃ³kezelÃ©s
- `data_lineage` - Data-model kapcsolatok
- `model_comparisons` - Model Ã¶sszehasonlÃ­tÃ¡sok
- `pipeline_events` - Pipeline esemÃ©nyek (info, warning, error)
- `notification_history` - Ã‰rtesÃ­tÃ©si elÅ‘zmÃ©nyek
- `data_drift_events` - Drift detection eredmÃ©nyek
- `model_monitoring` - Production monitoring
- `feature_statistics` - Feature store
- `ab_experiments` - A/B tesztek tracking

**View-k:**
- `latest_production_models` - Legfrissebb production modellek
- `recent_pipeline_events` - Friss pipeline esemÃ©nyek
- `model_performance_comparison` - Performance Ã¶sszehasonlÃ­tÃ¡s

**Python API:**
```python
from airflow.utils.metadata_tracker import MetadataTracker

with MetadataTracker(METADATA_DB_CONN) as tracker:
    run_id = tracker.create_model_run(...)
    tracker.log_metrics(run_id, {'r2_score': 0.87})
    tracker.log_parameters(run_id, {'n_estimators': 100})
```

### Multi-Channel Notification System

**3 csatorna:**
- **Email (SMTP/Gmail)** - HTML formÃ¡zott emailek szÃ­nkÃ³ddal
- **Slack (Webhooks)** - Rich formatting, emoji indicators
- **Database** - Audit trail Ã©s history tracking

**Notification tÃ­pusok:**
- Training start/success/failure
- Model deployment
- Model comparison results
- Data drift alerts
- Pipeline health issues

**KonfigurÃ¡lÃ¡s:**
```bash
# .env fÃ¡jlban
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password
TO_EMAILS=admin@example.com,team@example.com
SLACK_WEBHOOK_URL=https://hooks.slack.com/services/...
```

### Webhook Trigger API

**REST API service a DAG-ok triggerelÃ©sÃ©re:**

**Endpoints:**
- `GET /health` - Health check
- `POST /trigger/training` - Training trigger
- `POST /trigger/evaluation` - Evaluation trigger
- `GET /status/<dag_id>/<run_id>` - Status check
- `GET /dags` - Available DAGs

**Features:**
- API key authentication
- Request validation
- Callback URL support
- Airflow API wrapper

### Airflow UI ElÃ©rÃ©s

```bash
# Access Airflow UI
http://localhost:8081

# Login: admin / admin
# Toggle DAG switch to ON/OFF
```

## Monitoring Dashboard

### Real-time Monitoring with Streamlit

Access at http://localhost:8501

**Streamlit Dashboard komponensek:**

1. **Overview Page**
   - System health metrics
   - Recent training runs summary
   - Performance trends visualization
   - Active DAG status
   - Recent pipeline events

2. **Model Performance**
   - RÂ² Score trends over time
   - RMSE/MAE analysis
   - Model comparison charts
   - Best performing models
   - Training duration tracking

3. **Data Drift Detection**
   - **Evidently AI integration**
   - Feature distribution comparison (reference vs current)
   - Statistical drift tests (KS-test, Chi-square)
   - Population Stability Index (PSI)
   - HTML drift reports generation
   - Automatic drift alerts

4. **Model Registry**
   - Production model list
   - Model versions Ã©s stage tracking
   - Performance metrics comparison
   - Model deployment history
   - A/B experiment tracking

5. **Pipeline Monitoring**
   - DAG execution history
   - Task success/failure rates
   - Average execution times
   - Recent errors Ã©s warnings
   - Notification history

**Features:**
- Real-time data refresh
- Interactive Plotly visualizations
- MLflow integration
- Metadata database queries
- Export reports PDF/HTML formÃ¡tumban

## Teljes Projekt ÃttekintÃ©s

### Mi van a projektben?

Ez egy **komplett, production-ready MLOps platform**, amely demonstrÃ¡lja a modern gÃ©pi tanulÃ¡si rendszerek teljes Ã©letciklusÃ¡t:

#### ğŸ¤– Machine Learning
- **2 regressziÃ³s model:** Random Forest Ã©s Gradient Boosting
- **Preprocessing pipeline:** StandardScaler, feature engineering
- **Hyperparameter tuning:** GridSearchCV 10-fold CV-vel
- **Performance:** RÂ² ~0.47-0.49, RMSE ~0.57-0.58

#### ğŸ”„ MLOps Automation (Apache Airflow)
- **5 DAG kÃ¼lÃ¶nbÃ¶zÅ‘ trigger tÃ­pusokkal:**
  1. Schedule-based: Napi automatikus training (2 AM)
  2. Event-based: FileSensor Ãºj adatok detektÃ¡lÃ¡sÃ¡ra
  3. ExternalTaskSensor: DAG-ok kÃ¶zÃ¶tti fÃ¼ggÅ‘sÃ©gek
  4. Webhook: API-triggered training custom config-gal
  5. Orchestration: Multi-pipeline koordinÃ¡ciÃ³
- **Metadata tracking:** PostgreSQL 14 tÃ¡blÃ¡val
- **Multi-channel notifications:** Email (SMTP/Gmail), Slack, Database
- **Error handling:** Success/failure/retry callbacks

#### ğŸ“Š Model Tracking & Registry (MLflow)
- **Experiment tracking:** Metrics, parameters, artifacts
- **Model registry:** VerziÃ³kezelÃ©s, stage management
- **Model comparison:** Automated best model selection
- **Artifact storage:** Model persistence Ã©s versioning

#### ğŸŒ REST APIs (3 API)
1. **FastAPI** (8000) - Async predictions, Pydantic validation
2. **Flask-RESTX** (8000) - Traditional REST, mature ecosystem
3. **Webhook API** (8080) - DAG triggering, API key auth

**API Features:**
- Single & batch predictions
- Model training trigger
- Model metrics Ã©s management
- Health checks
- Swagger UI documentation

#### ğŸ“ˆ Monitoring & Visualization
- **Streamlit Dashboard** (8501):
  - Overview: System metrics, recent runs
  - Model Performance: RÂ² trends, RMSE analysis
  - Data Drift: Evidently integration, distribution comparison
  - Model Registry: Production models, versions
  - Pipeline Monitoring: DAG execution history, error tracking

#### ğŸ” Data Quality & Drift Detection
- **Automatic validation:** Schema, quality checks
- **Statistical tests:**
  - Kolmogorov-Smirnov test
  - Population Stability Index (PSI)
  - Chi-square test
- **Drift threshold:** PSI > 0.2
- **Automated retraining:** Conditional trigger drift esetÃ©n

#### ğŸ³ Docker Infrastructure
- **9 containerized services:**
  - Airflow (webserver + scheduler + init)
  - MLflow API
  - Webhook API
  - Streamlit monitoring
  - PostgreSQL (2 instance: Airflow + MLOps)
  - Redis (message broker)
- **Multi-service orchestration:** docker-compose
- **Shared volumes:** Models, data, logs, mlruns
- **Bridge network:** Service-to-service communication

#### ğŸ§ª Testing & Quality
- **91+ tests:** Unit, integration, API tests
- **Test coverage:** All modules tested
- **PEP8 compliant:** 0 linting errors
- **Code formatting:** Black, flake8
- **Type checking:** mypy support

#### ğŸ“¦ Data Pipeline
- **Dataset:** UCI Wine Quality (red wine)
- **Features:** 11 physicochemical properties
- **Target:** Quality score (0-10)
- **Split:** 80/20 train/test (stratified)
- **Preprocessing:** Standardization, optional PCA

#### ğŸ” Security & Configuration
- **Environment variables:** .env file
- **API authentication:** API key-based (Webhook API)
- **Database credentials:** Configurable
- **Secret management:** Not hardcoded
- **Production hardening:** TODO (HTTPS, JWT, rate limiting)

### Workflow Ã–sszefoglalÃ¡s

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Complete MLOps Workflow                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

1. Data Ingestion
   â””â”€â†’ FileSensor detektÃ¡lja Ãºj adatot
       â””â”€â†’ Data validation + drift detection

2. Model Training (3 trigger mÃ³d)
   â”œâ”€â†’ Schedule: Napi 2 AM automatikus
   â”œâ”€â†’ Event: Drift detekciÃ³ esetÃ©n
   â””â”€â†’ API: Webhook trigger external system-bÅ‘l

3. Tracking & Logging
   â”œâ”€â†’ MLflow: Experiments, runs, metrics, artifacts
   â””â”€â†’ PostgreSQL: Metadata, lineage, events, notifications

4. Model Comparison & Deployment
   â””â”€â†’ Compare new model vs production
       â”œâ”€â†’ Better? â†’ Deploy Staging â†’ Production
       â””â”€â†’ Not better? â†’ Send notification (no deploy)

5. Monitoring & Alerting
   â”œâ”€â†’ Streamlit: Real-time dashboard
   â”œâ”€â†’ Evidently: Drift detection
   â””â”€â†’ Notifications: Email + Slack + DB

6. Model Serving
   â””â”€â†’ FastAPI/Flask: REST API predictions
       â”œâ”€â†’ Single prediction
       â”œâ”€â†’ Batch predictions
       â””â”€â†’ Model management

7. External Integration
   â””â”€â†’ Webhook API: CI/CD, monitoring systems
       â””â”€â†’ Trigger training, evaluation, deployment
```

### TechnolÃ³giai Stack

**ML & Data Science:**
- scikit-learn, pandas, numpy, scipy
- Feature engineering, hyperparameter tuning

**MLOps & Orchestration:**
- Apache Airflow - Workflow automation
- MLflow - Experiment tracking & model registry
- Evidently AI - Data & model drift detection

**APIs & Web:**
- FastAPI - Modern async REST
- Flask-RESTX - Traditional REST
- Streamlit - Interactive dashboards

**Databases:**
- PostgreSQL - Airflow & MLOps metadata
- Redis - Message broker & caching

**Containerization:**
- Docker - Application containers
- Docker Compose - Multi-service orchestration

**Monitoring & Visualization:**
- Plotly - Interactive charts
- Evidently - Drift reports
- Custom dashboards

**Testing & Quality:**
- pytest - Testing framework
- black - Code formatting
- flake8 - Linting
- mypy - Type checking

**Notifications:**
- SMTP/Gmail - Email alerts
- Slack Webhooks - Chat notifications
- Database logging - Audit trail

### Projekt MÃ©retei

- **Total Code:** ~3,500+ lines Python
- **Test Code:** ~1,300 lines
- **API Code:** ~1,800 lines (2 prediction + 1 webhook API)
- **DAG Code:** ~1,500 lines (5 DAG-ok)
- **Tests:** 91+ test cases
- **Docker Services:** 9 containers
- **Database Tables:** 14 metadata tables
- **API Endpoints:** 30+ endpoints Ã¶sszesen

### HasznÃ¡lati PÃ©ldÃ¡k

**1. Training trigger scheduled:**
```bash
# Airflow automatikusan futtatja naponta 2 AM-kor
# Vagy manuÃ¡lisan:
docker-compose exec airflow-scheduler airflow dags trigger daily_model_training_with_notification
```

**2. Training trigger webhook-kel:**
```bash
curl -X POST http://localhost:8080/trigger/training \
  -H "X-API-Key: mlops-secret-key-2025" \
  -H "Content-Type: application/json" \
  -d '{"model_name": "wine_quality_rf_model", "trigger_source": "manual"}'
```

**3. Prediction:**
```bash
curl -X POST http://localhost:8000/predict \
  -H "Content-Type: application/json" \
  -d '{"features": {...}, "model_name": "rf"}'
```

**4. Monitoring:**
```bash
# Streamlit Dashboard
open http://localhost:8501

# MLflow UI
open http://localhost:5000

# Airflow UI
open http://localhost:8081
```

**5. Metadata query:**
```sql
-- Latest production models
SELECT * FROM latest_production_models;

-- Recent drift events
SELECT * FROM data_drift_events WHERE drift_detected = true;

-- Model performance comparison
SELECT * FROM model_performance_comparison ORDER BY performance_rank;
```

## Documentation

- **Main README:** This file - Teljes projekt Ã¡ttekintÃ©s
- **API Documentation:** [API_README.md](API_README.md) - 3 API rÃ©szletes dokumentÃ¡ciÃ³ja
- **Docker Guide:** [DOCKER_DEPLOYMENT.md](DOCKER_DEPLOYMENT.md) - Docker deployment
- **FastAPI Swagger:** http://localhost:8000/docs - Interactive API docs
- **Flask-RESTX Swagger:** http://localhost:8000/docs/ - Interactive API docs
- **Webhook API Swagger:** http://localhost:8080/docs - Webhook API docs
- **MLflow UI:** http://localhost:5000 - Experiment tracking
- **Airflow UI:** http://localhost:8081 - DAG monitoring
- **Streamlit Dashboard:** http://localhost:8501 - Real-time monitoring

## Troubleshooting

**Model not found:**
```bash
python main.py --pipeline compare
```

**Port in use:**
```bash
lsof -i :8000
kill -9 <PID>
```

**Import errors:**
```bash
cd wine_quality_mlops
source venv/bin/activate
pip install -r requirements.txt
```

## Contributing

1. Follow PEP8
2. Add tests for new features
3. Update documentation
4. Run `pytest tests/ -v` before commit
5. Check with `flake8 .`

## License

MIT License

## Status

**Production Ready - Full MLSecOps Platform**
- Version: 2.0.0
- Last Updated: January 2025
- Status: Stable

### Recent Updates (v2.0.0)

- Docker multi-container orchestration
- Apache Airflow automated training pipelines
- Streamlit monitoring dashboard
- Evidently data/model drift detection
- Complete MLSecOps infrastructure
- Production-ready deployment

---

## Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Wine Quality MLOps Platform                     â”‚
â”‚                     (Docker Compose Multi-Service)                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                                    â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Airflow    â”‚  â”‚  MLflow UI  â”‚  â”‚ Streamlit   â”‚  â”‚Webhook â”‚ â”‚
â”‚  â”‚  Webserver  â”‚  â”‚  + FastAPI  â”‚  â”‚  Dashboard  â”‚  â”‚  API   â”‚ â”‚
â”‚  â”‚   (8081)    â”‚  â”‚   (5000)    â”‚  â”‚   (8501)    â”‚  â”‚ (8080) â”‚ â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚        â”‚ â”‚
â”‚  â”‚â€¢ DAG UI     â”‚  â”‚â€¢ Tracking   â”‚  â”‚â€¢ Monitoring â”‚  â”‚â€¢ Triggerâ”‚ â”‚
â”‚  â”‚â€¢ Scheduling â”‚  â”‚â€¢ Registry   â”‚  â”‚â€¢ Drift Det. â”‚  â”‚â€¢ REST  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â”‚
â”‚         â”‚                â”‚                â”‚              â”‚      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â” â”‚
â”‚  â”‚                    Shared Volumes                           â”‚ â”‚
â”‚  â”‚  /models  /mlruns  /data  /logs  /airflow                  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”˜ â”‚
â”‚         â”‚                â”‚                â”‚              â”‚      â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”´â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Airflow    â”‚  â”‚ PostgreSQL  â”‚  â”‚ PostgreSQL  â”‚  â”‚ Redis â”‚ â”‚
â”‚  â”‚  Scheduler  â”‚  â”‚  (Airflow)  â”‚  â”‚  (MLOps)    â”‚  â”‚       â”‚ â”‚
â”‚  â”‚             â”‚  â”‚   (5432)    â”‚  â”‚   (5433)    â”‚  â”‚(6379) â”‚ â”‚
â”‚  â”‚             â”‚  â”‚             â”‚  â”‚             â”‚  â”‚       â”‚ â”‚
â”‚  â”‚â€¢ Dag Runs   â”‚  â”‚â€¢ Airflow    â”‚  â”‚â€¢ Metadata   â”‚  â”‚â€¢ Queueâ”‚ â”‚
â”‚  â”‚â€¢ Tasks      â”‚  â”‚  Metadata   â”‚  â”‚â€¢ Tracking   â”‚  â”‚â€¢ Cacheâ”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                                                    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Data Flow:
1. Airflow Scheduler â†’ DAG Tasks vÃ©grehajtÃ¡s
2. Tasks â†’ MLflow tracking (experiments, runs, metrics)
3. Tasks â†’ MLOps Metadata DB (pipeline events, model runs, metrics)
4. Webhook API â†’ Airflow API â†’ DAG trigger
5. Streamlit â†’ MLflow + MLOps DB â†’ Real-time visualization
6. FastAPI/Flask â†’ Models â†’ Predictions
```

### Docker Services Ã–sszefoglalÃ¡s

**9 Docker Service:**

1. **postgres** - Airflow metadata database
2. **mlops-metadata-db** - MLOps tracking database (**DedikÃ¡lt MLOps DB**)
3. **redis** - Airflow Celery backend
4. **airflow-webserver** - Airflow UI (8081)
5. **airflow-scheduler** - DAG scheduling engine
6. **airflow-init** - Database initialization
7. **mlflow-api** - MLflow tracking + FastAPI/Flask (5000, 8000)
8. **streamlit-monitoring** - Monitoring dashboard (8501)
9. **webhook-api** - Webhook trigger service (8080)

**Volumes:**
- `./airflow/dags` â†’ `/opt/airflow/dags`
- `./models` â†’ `/app/models`
- `./mlruns` â†’ `/app/mlruns`
- `./data` â†’ `/app/data` Ã©s `/opt/airflow/data`
- `./logs` â†’ `/app/logs`

**Networks:**
- `mlops-network` - Bridge network Ã¶sszes service szÃ¡mÃ¡ra

---

## Cloud Deployment - GCP Cloud Run

A projekt tÃ¡mogatja **Google Cloud Platform Cloud Run** deployment-et automatikus CI/CD pipeline-nal.

### JellemzÅ‘k

- Serverless autoscaling (0-10 instances)
- Automatikus CI/CD GitHub Actions-szel
- Production-ready konfigurÃ¡ciÃ³
- KÃ¶ltsÃ©ghatÃ©kony (pay-per-use, free tier elÃ©rhetÅ‘)
- HTTPS endpoint automatikus SSL-lel

### Gyors Setup

```bash
# 1. GCP kÃ¶rnyezet beÃ¡llÃ­tÃ¡sa
export GCP_PROJECT_ID="your-project-id"
./gcp/setup-gcp.sh

# 2. GitHub Secrets beÃ¡llÃ­tÃ¡sa
# - GCP_PROJECT_ID: your-project-id
# - GCP_SA_KEY: (gcp-sa-key.json tartalma)

# 3. Deploy
git push origin main  # Automatikus deployment
# vagy
./gcp/deploy.sh      # ManuÃ¡lis deployment
```

### Monitoring

```bash
# InteraktÃ­v monitoring tool
./gcp/monitor.sh

# Real-time logs
gcloud logging tail "resource.type=cloud_run_revision"
```

### DokumentÃ¡ciÃ³

- **Teljes ÃºtmutatÃ³**: [GCP_DEPLOYMENT_GUIDE.md](GCP_DEPLOYMENT_GUIDE.md) - RÃ©szletes deployment guide
- **Gyors ÃºtmutatÃ³**: [gcp/QUICK_START.md](gcp/QUICK_START.md) - 5 perces setup
- **ImplementÃ¡ciÃ³**: [GCP_IMPLEMENTATION_SUMMARY.md](GCP_IMPLEMENTATION_SUMMARY.md) - ArchitektÃºra Ã©s Ã¶sszefoglalÃ³

---

For detailed API documentation, see [API_README.md](API_README.md)
